{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center><font size=6>CS490: Machine Learning<br>Homework 1</font></center>**\n",
    "\n",
    "In this assignment, you will create a kNN classifier for the Fisher Iris dataset. You will not have to create a kNN learning from scratch; rather, you will use the kNN learner provided in the mltools library. However, you may find it helpful to explore the provided kNN implementation and understand how it works. \n",
    "\n",
    "The sections below will take you through the machine learning process as follows:\n",
    "1. Divide the data into training and validation sets\n",
    "2. Learn a classifier for k nearest neighbors\n",
    "3. Measure the prediction error for your classifier\n",
    "4. Repeat steps 2 and 3 for different values of k to find the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up the Data\n",
    "The first step in creating your classifier is to load the data. \n",
    "As before, you will be using the \"Fisher iris\" data set (in the `data` directory). Run the following block to load the iris data into your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = np.genfromtxt(\"data/iris.txt\",delimiter=None)  # load the data\n",
    "Y = iris[:,-1]              # target value (iris species) is the last column\n",
    "X = iris[:,0:-1]            # features are the other columns\n",
    "# Note: indexing with \":\" indicates all values (in this case, all rows);\n",
    "#  indexing with a value (\"0\", \"1\", \"-1\", etc.) extracts only that value (here, columns);\n",
    "#  indexing rows/columns with a range (\"1:-1\") extracts any row/column in that range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will shuffle and split the data into training and validation subsets. We shuffle the data to randomize which data points end up as training data and which end up as validation to try and remove any potential bias introduced by the order the data is stored in the file.\n",
    "\n",
    "To do this, we will be using some data manipulation routines from the provided class code (`mltools`). Run the block of code below to shuffle the data and divide it into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltools as ml\n",
    "\n",
    "np.random.seed(0)           # set the random number seed\n",
    "X,Y = ml.shuffleData(X,Y)  # shuffle data randomly\n",
    "# (This is a good idea in case your data are ordered in some systematic way.)\n",
    "\n",
    "Xtrain,Xval,Ytrain,Yval = ml.splitData(X,Y, 0.75)  # split data into 75/25 train/validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to set the random number seed to 0 before calling `shuffleData` as in the example above (and in general, for every assignment). This ensures consistent behavior each time the code is run.\n",
    "\n",
    "# kNN Learning\n",
    "Our learners (the parameterized functions that do the prediction) will be defined as python objects, based on either a generic classifier or generic regressor class.  The base classes\n",
    "have a few useful functions, such as computing error rates or other measures of quality.  More\n",
    "importantly, the learners  all follow a generic behavioral pattern, allowing us to train\n",
    "the function on one data set (i.e., set the parameters of the model to perform well on those data),\n",
    "and then make predictions on another data set.\n",
    "\n",
    "You can now build and *train* a kNN classifier on {Xtrain,Ytrain} and make predictions on some data {Xval} with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1                         # set an initial value for K\n",
    "knn = ml.knn.knnClassify()    # create the object and train it\n",
    "knn.train(Xtrain, Ytrain, K)  # where K is an integer, e.g. 1 for nearest neighbor prediction\n",
    "YvalHat = knn.predict(Xval)   # get estimates of y for each data point in Xval\n",
    "print(YvalHat)\n",
    "\n",
    "# Alternatively, the constructor provides a shortcut to \"train\":\n",
    "knn = ml.knn.knnClassify( Xtrain, Ytrain, K )\n",
    "YvalHat = knn.predict(Xval)\n",
    "print(YvalHat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your data are 2D, you can visualize the data set and a classifier's decision regions using the function `plotClassify2D`. Our data is currently 4D (i.e., the iris data has 4 features that are measured), so we can train another version of the classifier using just the first two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2D = ml.knn.knnClassify( Xtrain[:,:2], Ytrain, K )\n",
    "ml.plotClassify2D( knn2D, Xtrain[:,0:2], Ytrain)  # make 2D classification plot with data (Xtr,Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function plots the training data and colored points as per their labels, then calls knn's predict function\n",
    "on a densely spaced grid of points in the 2D space, and uses this to produce the background color.\n",
    "Calling the function with knn=None will plot only the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.plotClassify2D( None, Xtrain[:,0:2], Ytrain) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Activity 1: Training a Classifier\n",
    "Using the code above as an example, train a kNN classifier that uses only the first two features of X\n",
    "(e.g., let X be only the first two columns of iris, instead of the first four) and visualize (plot) the classification boundary for varying values of K=[1, 5, 10, 50] using plotClassify2D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=[1, 5, 10, 50]\n",
    "\n",
    "for i, k in enumerate(K):\n",
    "    \n",
    "    # TODO: build and train classifier using the first two features of Xtrain\n",
    "    \n",
    "    # TODO: plot decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating kNN\n",
    "After we've trained a model, we want to evaluate how well it performs, both on the training data and the validation data. To do this for our classification problem, we will compute the error rate (number of misclassifications). We can do this manually by generating predictions for our training and validation data based on the the classifier and comparing to the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YtrainHat = knn2D.predict(Xtrain[:,:2])   # get estimates of y for each data point in Xtrain using our 2D kNN model\n",
    "YvalHat = knn2D.predict(Xval[:,:2])     # get estimates of y for each data point in Xval\n",
    "\n",
    "errT = np.sum(YtrainHat != Ytrain)/Ytrain.shape[0]      # get proportion of times the prediction doesn't match training\n",
    "errV = np.sum(YvalHat != Yval)/Yval.shape[0]            # get proportion of times the prediction doesn't match validation\n",
    "\n",
    "print(errT, errV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mltools also contains a function that will do this comparison for us to generate the error rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn2D.err(Xtrain[:,:2],Ytrain), knn2D.err(Xval[:,:2],Yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 2: Measuring Prediction Error \n",
    "Again using only the first two features, compute the error rate (number of misclassifications) on both the training and validation data as a function of K=[1, 2, 5, 10, 50, 100, 200].\n",
    "\n",
    "Plot the resulting error rate functions with training error in red and validation error in green. You may find it useful to use a [semi-log plot](https://en.wikipedia.org/wiki/Semi-log_plot) to deal with the very different scales of the x-axis (K from 1 to 200) and the y-axis (error rate between 0 and 1). matplotlib will do the linear-log conversion for you with the [semilogx function](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.semilogx.html).\n",
    "\n",
    "You can do this most easily with a for-loop like the one below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=[1, 2, 5, 10, 50, 100, 200]\n",
    "errTr = np.zeros(len(K))      # array for the training error of each k initialized to all zeros\n",
    "errVa = np.zeros(len(K))      # array for the validation error of each k initialized to all zeros \n",
    "\n",
    "for i, k in enumerate(K):\n",
    "        \n",
    "    # TODO: build and train classifier using the first two features of Xtrain for the current value of k\n",
    "    \n",
    "    # TODO: Compute error for training and save in errTr[i]\n",
    "    \n",
    "    # TODO: Compute error for validation and save in errTr[i]\n",
    "    \n",
    "\n",
    "# TODO: plot training errors in red\n",
    "\n",
    "# TODO: plot validation errors in green\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Based on these plots, what value of K would you recommend? Why?**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 3: Retraining the Model\n",
    "Create the same error rate plots as the previous part, but with all the features in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Retrain the classifiers with varying values for k using all\n",
    "# four features in the iris data and plot the prediction error results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Are the plots very different? Is your recommendation for the best K different?**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statement of Collaboration\n",
    "All students are required to follow the academic honesty guidelines presented in the course syllabus.\n",
    "For homework assignments, I encourage students to organize to discuss the task descriptions, requirements, possible bugs in the support code, and the relevant technical content *before* they start working on it. However, the final submission must be your own work. \n",
    "    \n",
    "Please provide a brief statement of collaboration, including the names of everyone involved in any discussions (especially in-person ones), and what was discussed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
